{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble: load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branches: ['sim_pt', 'sim_eta', 'sim_phi', 'sim_pca_dxy', 'sim_pca_dz', 'sim_q', 'sim_event', 'sim_pdgId', 'sim_vx', 'sim_vy', 'sim_vz', 'sim_trkNtupIdx', 'sim_TC_matched', 'sim_TC_matched_mask', 'tc_pt', 'tc_eta', 'tc_phi', 'tc_type', 'tc_isFake', 'tc_isDuplicate', 'tc_matched_simIdx', 'sim_dummy', 'tc_dummy', 'pT5_matched_simIdx', 'pT5_hitIdxs', 'sim_pT5_matched', 'pT5_pt', 'pT5_eta', 'pT5_phi', 'pT5_isFake', 't5_sim_vxy', 't5_sim_vz', 'pT5_isDuplicate', 'pT5_score', 'pT5_layer_binary', 'pT5_moduleType_binary', 'pT5_matched_pt', 'pT5_rzChiSquared', 'pT5_rPhiChiSquared', 'pT5_rPhiChiSquaredInwards', 'sim_pT3_matched', 'pT3_pt', 'pT3_isFake', 'pT3_isDuplicate', 'pT3_eta', 'pT3_phi', 'pT3_score', 'pT3_foundDuplicate', 'pT3_matched_simIdx', 'pT3_hitIdxs', 'pT3_pixelRadius', 'pT3_pixelRadiusError', 'pT3_matched_pt', 'pT3_tripletRadius', 'pT3_rPhiChiSquared', 'pT3_rPhiChiSquaredInwards', 'pT3_rzChiSquared', 'pT3_layer_binary', 'pT3_moduleType_binary', 'sim_pLS_matched', 'pLS_matched_simIdx', 'pLS_isFake', 'pLS_isDuplicate', 'pLS_ptIn', 'pLS_ptErr', 'pLS_px', 'pLS_py', 'pLS_pz', 'pLS_eta', 'pLS_isQuad', 'pLS_etaErr', 'pLS_phi', 'pLS_score', 'pLS_circleCenterX', 'pLS_circleCenterY', 'pLS_circleRadius', 'sim_T5_matched', 't5_isFake', 't5_isDuplicate', 't5_foundDuplicate', 't5_pt', 't5_pMatched', 't5_eta', 't5_phi', 't5_score_rphisum', 't5_hitIdxs', 't5_matched_simIdx', 't5_moduleType_binary', 't5_layer_binary', 't5_matched_pt', 't5_innerRadius', 't5_outerRadius', 't5_bridgeRadius', 't5_chiSquared', 't5_rzChiSquared', 't5_isDupAlgoFlag', 't5_nonAnchorChiSquared', 't5_dBeta1', 't5_dBeta2', 'module_layers', 'module_subdets', 'module_rings', 'module_rods', 'module_modules', 'module_isTilted', 'module_eta', 'module_r', 'md_occupancies', 'sg_occupancies', 't3_occupancies', 'tc_occupancies', 't5_occupancies', 'pT3_occupancies', 'pT5_occupancies', 't5_t3_idx0', 't5_t3_idx1', 't5_tc_idx', 't5_partOfTC', 't5_t3_pt', 't5_t3_eta', 't5_t3_phi', 't5_t3_fakeScore1', 't5_t3_promptScore1', 't5_t3_displacedScore1', 't5_t3_fakeScore2', 't5_t3_promptScore2', 't5_t3_displacedScore2', 't5_t3_0_r', 't5_t3_0_x', 't5_t3_0_y', 't5_t3_0_z', 't5_t3_0_eta', 't5_t3_0_phi', 't5_t3_0_detId', 't5_t3_0_layer', 't5_t3_0_moduleType', 't5_t3_1_r', 't5_t3_1_x', 't5_t3_1_y', 't5_t3_1_z', 't5_t3_1_eta', 't5_t3_1_phi', 't5_t3_1_detId', 't5_t3_1_layer', 't5_t3_1_moduleType', 't5_t3_2_r', 't5_t3_2_x', 't5_t3_2_y', 't5_t3_2_z', 't5_t3_2_eta', 't5_t3_2_phi', 't5_t3_2_detId', 't5_t3_2_layer', 't5_t3_2_moduleType', 't5_t3_3_r', 't5_t3_3_x', 't5_t3_3_y', 't5_t3_3_z', 't5_t3_3_eta', 't5_t3_3_phi', 't5_t3_3_detId', 't5_t3_3_layer', 't5_t3_3_moduleType', 't5_t3_4_r', 't5_t3_4_x', 't5_t3_4_y', 't5_t3_4_z', 't5_t3_4_eta', 't5_t3_4_phi', 't5_t3_4_detId', 't5_t3_4_layer', 't5_t3_4_moduleType', 't5_t3_5_r', 't5_t3_5_x', 't5_t3_5_y', 't5_t3_5_z', 't5_t3_5_eta', 't5_t3_5_phi', 't5_t3_5_detId', 't5_t3_5_layer', 't5_t3_5_moduleType', 't3_betaIn', 't3_centerX', 't3_centerY', 't3_radius', 't3_partOfPT5', 't3_partOfT5', 't3_partOfPT3', 't3_pMatched', 't3_sim_vxy', 't3_sim_vz', 't3_hit_0_r', 't3_hit_0_x', 't3_hit_0_y', 't3_hit_0_z', 't3_hit_0_eta', 't3_hit_0_phi', 't3_hit_0_detId', 't3_hit_0_layer', 't3_hit_0_moduleType', 't3_hit_1_r', 't3_hit_1_x', 't3_hit_1_y', 't3_hit_1_z', 't3_hit_1_eta', 't3_hit_1_phi', 't3_hit_1_detId', 't3_hit_1_layer', 't3_hit_1_moduleType', 't3_hit_2_r', 't3_hit_2_x', 't3_hit_2_y', 't3_hit_2_z', 't3_hit_2_eta', 't3_hit_2_phi', 't3_hit_2_detId', 't3_hit_2_layer', 't3_hit_2_moduleType', 't3_hit_3_r', 't3_hit_3_x', 't3_hit_3_y', 't3_hit_3_z', 't3_hit_3_eta', 't3_hit_3_phi', 't3_hit_3_detId', 't3_hit_3_layer', 't3_hit_3_moduleType', 't3_hit_4_r', 't3_hit_4_x', 't3_hit_4_y', 't3_hit_4_z', 't3_hit_4_eta', 't3_hit_4_phi', 't3_hit_4_detId', 't3_hit_4_layer', 't3_hit_4_moduleType', 't3_hit_5_r', 't3_hit_5_x', 't3_hit_5_y', 't3_hit_5_z', 't3_hit_5_eta', 't3_hit_5_phi', 't3_hit_5_detId', 't3_hit_5_layer', 't3_hit_5_moduleType', 't3_layer_binary', 't3_matched_simIdx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import awkward as ak # Using awkward array for easier handling of jagged data\n",
    "import time # For timing steps\n",
    "\n",
    "def load_root_file(file_path, branches=None, print_branches=False):\n",
    "    all_branches = {}\n",
    "    with uproot.open(file_path) as file:\n",
    "        tree = file[\"tree\"]\n",
    "        # Load all ROOT branches into array if not specified\n",
    "        if branches is None:\n",
    "            branches = tree.keys()\n",
    "        # Option to print the branch names\n",
    "        if print_branches:\n",
    "            print(\"Branches:\", tree.keys())\n",
    "        # Each branch is added to the dictionary\n",
    "        for branch in branches:\n",
    "            try:\n",
    "                all_branches[branch] = (tree[branch].array(library=\"np\"))\n",
    "            except uproot.KeyInFileError as e:\n",
    "                print(f\"KeyInFileError: {e}\")\n",
    "        # Number of events in file\n",
    "        all_branches['event'] = tree.num_entries\n",
    "    return all_branches\n",
    "\n",
    "branches_list = [\n",
    "    't5_innerRadius',\n",
    "    't5_bridgeRadius',\n",
    "    't5_outerRadius',\n",
    "    't5_pt',\n",
    "    't5_eta',\n",
    "    't5_phi',\n",
    "    't5_isFake',\n",
    "    't5_t3_idx0',\n",
    "    't5_t3_idx1',\n",
    "\n",
    "    't5_t3_fakeScore1',\n",
    "    't5_t3_promptScore1',\n",
    "    't5_t3_displacedScore1',\n",
    "    't5_t3_fakeScore2',\n",
    "    't5_t3_promptScore2',\n",
    "    't5_t3_displacedScore2',\n",
    "\n",
    "    't5_pMatched',\n",
    "    't5_sim_vxy',\n",
    "    't5_sim_vz',\n",
    "    't5_matched_simIdx'\n",
    "]\n",
    "\n",
    "branches_list += [\n",
    "    'pLS_eta',\n",
    "    'pLS_etaErr',\n",
    "    'pLS_phi',\n",
    "    'pLS_matched_simIdx',\n",
    "    'pLS_circleCenterX',\n",
    "    'pLS_circleCenterY',\n",
    "    'pLS_circleRadius',\n",
    "    'pLS_ptIn',\n",
    "    'pLS_ptErr',\n",
    "    'pLS_px',\n",
    "    'pLS_py',\n",
    "    'pLS_pz',\n",
    "    'pLS_isQuad',\n",
    "    'pLS_isFake'\n",
    "]\n",
    "\n",
    "# Hit-dependent branches\n",
    "suffixes = ['r', 'z', 'eta', 'phi', 'layer']\n",
    "branches_list += [f't5_t3_{i}_{suffix}' for i in [0, 2, 4] for suffix in suffixes]\n",
    "\n",
    "file_path = \"pls_t5_embed.root\"\n",
    "branches = load_root_file(file_path, branches_list, print_branches=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z max: 267.2349853515625, R max: 110.10993957519531, Eta max: 2.5\n"
     ]
    }
   ],
   "source": [
    "z_max = np.max([np.max(event) for event in branches[f't5_t3_4_z']])\n",
    "r_max = np.max([np.max(event) for event in branches[f't5_t3_4_r']])\n",
    "eta_max = 2.5\n",
    "phi_max = np.pi\n",
    "n_events = np.shape(branches['t5_pt'])[0]\n",
    "\n",
    "print(f'Z max: {z_max}, R max: {r_max}, Eta max: {eta_max}')\n",
    "\n",
    "def delta_phi(phi1, phi2):\n",
    "    delta = phi1 - phi2\n",
    "    # Adjust delta to be within the range [-pi, pi]\n",
    "    if delta > np.pi:\n",
    "        delta -= 2 * np.pi\n",
    "    elif delta < -np.pi:\n",
    "        delta += 2 * np.pi\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble: T5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building T5 features  (pMatched ≥ 0.0) …\n",
      "\n",
      "Kept 3630781 / 3630781 T5s (100.00 %) that passed the pMatched cut.\n",
      "Total events with ≥1 kept T5: 500\n"
     ]
    }
   ],
   "source": [
    "pMATCHED_THRESHOLD = 0.        # keep if t5_pMatched ≥ this\n",
    "print(f\"\\nBuilding T5 features  (pMatched ≥ {pMATCHED_THRESHOLD}) …\")\n",
    "\n",
    "features_per_event    = []\n",
    "eta_per_event         = []\n",
    "displaced_per_event = []\n",
    "sim_indices_per_event = []\n",
    "\n",
    "kept_tot, init_tot = 0, 0\n",
    "for ev in range(n_events):\n",
    "\n",
    "    n_t5 = len(branches['t5_t3_idx0'][ev])\n",
    "    init_tot += n_t5\n",
    "    if n_t5 == 0:\n",
    "        continue\n",
    "\n",
    "    feat_evt = []\n",
    "    eta_evt  = []\n",
    "    sim_evt  = []\n",
    "    disp_evt = []\n",
    "\n",
    "    for i in range(n_t5):\n",
    "        if branches['t5_pMatched'][ev][i] < pMATCHED_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        idx0 = branches['t5_t3_idx0'][ev][i]\n",
    "        idx1 = branches['t5_t3_idx1'][ev][i]\n",
    "\n",
    "        # hit-level quantities -------------------------------------------------\n",
    "        eta1 = (branches['t5_t3_0_eta'][ev][idx0])\n",
    "        eta2 = abs(branches['t5_t3_2_eta'][ev][idx0])\n",
    "        eta3 = abs(branches['t5_t3_4_eta'][ev][idx0])\n",
    "        eta4 = abs(branches['t5_t3_2_eta'][ev][idx1])\n",
    "        eta5 = abs(branches['t5_t3_4_eta'][ev][idx1])\n",
    "\n",
    "        phi1 = branches['t5_t3_0_phi'][ev][idx0]\n",
    "        phi2 = branches['t5_t3_2_phi'][ev][idx0]\n",
    "        phi3 = branches['t5_t3_4_phi'][ev][idx0]\n",
    "        phi4 = branches['t5_t3_2_phi'][ev][idx1]\n",
    "        phi5 = branches['t5_t3_4_phi'][ev][idx1]\n",
    "\n",
    "        z1 = abs(branches['t5_t3_0_z'][ev][idx0])\n",
    "        z2 = abs(branches['t5_t3_2_z'][ev][idx0])\n",
    "        z3 = abs(branches['t5_t3_4_z'][ev][idx0])\n",
    "        z4 = abs(branches['t5_t3_2_z'][ev][idx1])\n",
    "        z5 = abs(branches['t5_t3_4_z'][ev][idx1])\n",
    "\n",
    "        r1 = branches['t5_t3_0_r'][ev][idx0]\n",
    "        r2 = branches['t5_t3_2_r'][ev][idx0]\n",
    "        r3 = branches['t5_t3_4_r'][ev][idx0]\n",
    "        r4 = branches['t5_t3_2_r'][ev][idx1]\n",
    "        r5 = branches['t5_t3_4_r'][ev][idx1]\n",
    "\n",
    "        inR  = branches['t5_innerRadius' ][ev][i]\n",
    "        brR  = branches['t5_bridgeRadius'][ev][i]\n",
    "        outR = branches['t5_outerRadius' ][ev][i]\n",
    "\n",
    "        s1_fake   = branches['t5_t3_fakeScore1'     ][ev][i]\n",
    "        s1_prompt = branches['t5_t3_promptScore1'   ][ev][i]\n",
    "        s1_disp   = branches['t5_t3_displacedScore1'][ev][i]\n",
    "        d_fake    = branches['t5_t3_fakeScore2'     ][ev][i] - s1_fake\n",
    "        d_prompt  = branches['t5_t3_promptScore2'   ][ev][i] - s1_prompt\n",
    "        d_disp    = branches['t5_t3_displacedScore2'][ev][i] - s1_disp\n",
    "\n",
    "        f = [\n",
    "            eta1 / eta_max,\n",
    "            np.cos(phi1),\n",
    "            np.sin(phi1),\n",
    "            z1 / z_max,\n",
    "            r1 / r_max,\n",
    "\n",
    "            eta2 - abs(eta1),\n",
    "            delta_phi(phi2, phi1),\n",
    "            (z2 - z1) / z_max,\n",
    "            (r2 - r1) / r_max,\n",
    "\n",
    "            eta3 - eta2,\n",
    "            delta_phi(phi3, phi2),\n",
    "            (z3 - z2) / z_max,\n",
    "            (r3 - r2) / r_max,\n",
    "\n",
    "            eta4 - eta3,\n",
    "            delta_phi(phi4, phi3),\n",
    "            (z4 - z3) / z_max,\n",
    "            (r4 - r3) / r_max,\n",
    "\n",
    "            eta5 - eta4,\n",
    "            delta_phi(phi5, phi4),\n",
    "            (z5 - z4) / z_max,\n",
    "            (r5 - r4) / r_max,\n",
    "\n",
    "            1.0 / inR,\n",
    "            1.0 / brR,\n",
    "            1.0 / outR,\n",
    "\n",
    "            s1_fake, s1_prompt, s1_disp,\n",
    "            d_fake,  d_prompt,  d_disp\n",
    "        ]\n",
    "        feat_evt.append(f)\n",
    "        eta_evt.append(eta1)\n",
    "        disp_evt.append(branches['t5_sim_vxy'][ev][i])\n",
    "\n",
    "        # first (or only) matched sim-index, -1 if none -----------------------\n",
    "        simIdx_list = branches['t5_matched_simIdx'][ev][i]\n",
    "        sim_evt.append(simIdx_list[0] if len(simIdx_list) else -1)\n",
    "\n",
    "    # push to global containers ----------------------------------------------\n",
    "    if feat_evt:                                # skip events with no survivors\n",
    "        features_per_event.append(np.asarray(feat_evt, dtype=np.float32))\n",
    "        eta_per_event.append(np.asarray(eta_evt,  dtype=np.float32))\n",
    "        displaced_per_event.append(np.asarray(disp_evt, dtype=np.float32))\n",
    "        sim_indices_per_event.append(np.asarray(sim_evt, dtype=np.int64))\n",
    "        kept_tot += len(feat_evt)\n",
    "\n",
    "print(f\"\\nKept {kept_tot} / {init_tot} T5s \"\n",
    "      f\"({kept_tot/init_tot*100:.2f} %) that passed the pMatched cut.\")\n",
    "print(f\"Total events with ≥1 kept T5: {len(features_per_event)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble: PLS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building pLS features …\n",
      "\n",
      "Kept 3721929 / 11314631 pLSs (32.89 %) that passed the selections.\n",
      "Total events with ≥1 kept pLS: 500\n"
     ]
    }
   ],
   "source": [
    "KEEP_FRAC_PLS = 0.40\n",
    "print(f\"\\nBuilding pLS features …\")\n",
    "\n",
    "pLS_features_per_event    = []\n",
    "pLS_eta_per_event         = []\n",
    "pLS_sim_indices_per_event = []\n",
    "\n",
    "kept_tot_pls, init_tot_pls = 0, 0\n",
    "for ev in range(n_events):\n",
    "    n_pls = len(branches['pLS_eta'][ev])\n",
    "    init_tot_pls += n_pls\n",
    "    if n_pls == 0:\n",
    "        continue\n",
    "\n",
    "    feat_evt, eta_evt, sim_evt = [], [], []\n",
    "\n",
    "    for i in range(n_pls):\n",
    "        if branches['pLS_isFake'][ev][i]:\n",
    "            continue\n",
    "        if np.random.random() > KEEP_FRAC_PLS:\n",
    "            continue\n",
    "\n",
    "        # ――― hit‑level quantities -------------------------------------------\n",
    "        eta = branches['pLS_eta'][ev][i]\n",
    "        etaErr = branches['pLS_etaErr'][ev][i]\n",
    "        phi = branches['pLS_phi'][ev][i]\n",
    "        circleCenterX = np.abs(branches['pLS_circleCenterX'][ev][i])\n",
    "        circleCenterY = np.abs(branches['pLS_circleCenterY'][ev][i])\n",
    "        circleRadius = branches['pLS_circleRadius'][ev][i]\n",
    "        ptIn = branches['pLS_ptIn'][ev][i]\n",
    "        ptErr = branches['pLS_ptErr'][ev][i]\n",
    "        isQuad = branches['pLS_isQuad'][ev][i]\n",
    "\n",
    "        # ――― build feature vector -------------------------------------------\n",
    "        f = [\n",
    "            eta/4.0,\n",
    "            etaErr/.00139,\n",
    "            np.cos(phi),\n",
    "            np.sin(phi),\n",
    "            1.0 / ptIn,\n",
    "            np.log10(ptErr),\n",
    "            isQuad,\n",
    "            np.log10(circleCenterX),\n",
    "            np.log10(circleCenterY),\n",
    "            np.log10(circleRadius),\n",
    "        ]\n",
    "\n",
    "        feat_evt.append(f)\n",
    "        eta_evt.append(eta)\n",
    "\n",
    "        sim_list = branches['pLS_matched_simIdx'][ev][i]\n",
    "        sim_evt.append(sim_list[0] if len(sim_list) else -1)\n",
    "\n",
    "    # ――― store per‑event containers -----------------------------------------\n",
    "    if feat_evt:              # skip events with no survivors\n",
    "        pLS_features_per_event   .append(np.asarray(feat_evt, dtype=np.float32))\n",
    "        pLS_eta_per_event        .append(np.asarray(eta_evt,  dtype=np.float32))\n",
    "        pLS_sim_indices_per_event.append(np.asarray(sim_evt, dtype=np.int64))\n",
    "        kept_tot_pls += len(feat_evt)\n",
    "\n",
    "print(f\"\\nKept {kept_tot_pls} / {init_tot_pls} pLSs \"\n",
    "      f\"({kept_tot_pls/init_tot_pls*100:.2f} %) that passed the selections.\")\n",
    "print(f\"Total events with ≥1 kept pLS: {len(pLS_features_per_event)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-T5 pairs, for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random, math, numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DELTA_R2_CUT = 0.02\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "def _delta_phi(phi1, phi2):\n",
    "    \"\"\"same helper you already defined, but inline for the worker\"\"\"\n",
    "    d = phi1 - phi2\n",
    "    if d > math.pi:\n",
    "        d -= 2 * math.pi\n",
    "    elif d < -math.pi:\n",
    "        d += 2 * math.pi\n",
    "    return d\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "def _pairs_single_event(evt_idx,\n",
    "                        F, S, D,\n",
    "                        max_sim, max_dis,\n",
    "                        invalid_sim):\n",
    "    \"\"\"\n",
    "    Worker run in a separate process.\n",
    "    Returns two Python lists with the selected (i,j) indices per event.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    n = F.shape[0]\n",
    "    if n < 2:\n",
    "        return evt_idx, [], []\n",
    "\n",
    "    eta1 = F[:, 0] * eta_max\n",
    "    phi1 = np.arctan2(F[:, 2], F[:, 1])\n",
    "\n",
    "    sim_pairs, dis_pairs = [], []\n",
    "\n",
    "    # similar pairs (same sim-index)\n",
    "    buckets = {}\n",
    "    for idx, s in enumerate(S):\n",
    "        if s != invalid_sim:\n",
    "            buckets.setdefault(s, []).append(idx)\n",
    "\n",
    "    for lst in buckets.values():\n",
    "        if len(lst) < 2:\n",
    "            continue\n",
    "        for a in range(len(lst) - 1):\n",
    "            i = lst[a]\n",
    "            for b in range(a + 1, len(lst)):\n",
    "                j = lst[b]\n",
    "                dphi = _delta_phi(phi1[i], phi1[j])\n",
    "                dr2  = (eta1[i] - eta1[j])**2 + dphi**2\n",
    "                if dr2 < DELTA_R2_CUT:\n",
    "                    sim_pairs.append((i, j))\n",
    "\n",
    "    # dissimilar pairs (different sim)\n",
    "    for i in range(n - 1):\n",
    "        si, ei, pi = S[i], eta1[i], phi1[i]\n",
    "        for j in range(i + 1, n):\n",
    "            # skip fake-fake pairs\n",
    "            if si == invalid_sim and S[j] == invalid_sim:\n",
    "                continue\n",
    "            if (si == S[j]) and si != invalid_sim:\n",
    "                continue\n",
    "            dphi = _delta_phi(pi, phi1[j])\n",
    "            dr2  = (ei - eta1[j])**2 + dphi**2\n",
    "            if dr2 < DELTA_R2_CUT:\n",
    "                dis_pairs.append((i, j))\n",
    "\n",
    "    # down-sample\n",
    "    if len(sim_pairs) > max_sim:\n",
    "        sim_pairs = random.sample(sim_pairs, max_sim)\n",
    "    if len(dis_pairs) > max_dis:\n",
    "        dis_pairs = random.sample(dis_pairs, max_dis)\n",
    "\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[evt {evt_idx:4d}]  T5s={n:5d}  sim={len(sim_pairs):3d}  dis={len(dis_pairs):3d} | {dt:.1f} seconds\")\n",
    "    return evt_idx, sim_pairs, dis_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-T5 pairs, vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "DELTA_R2_CUT = 0.02\n",
    "\n",
    "def _pairs_single_event_vectorized(evt_idx,\n",
    "                                   F, S, D,\n",
    "                                   max_sim, max_dis,\n",
    "                                   invalid_sim):\n",
    "    t0 = time.time()\n",
    "    n = F.shape[0]\n",
    "    eta1, phi1 = F[:, 0] * eta_max, np.arctan2(F[:, 2], F[:, 1])\n",
    "\n",
    "    # upper-triangle (non-diagonal) indices\n",
    "    idx_l, idx_r = np.triu_indices(n, k=1)\n",
    "    idxs_triu = np.stack((idx_l, idx_r), axis=-1)\n",
    "\n",
    "    simidx_l = S[idx_l]\n",
    "    simidx_r = S[idx_r]\n",
    "\n",
    "    eta_l = eta1[idx_l]\n",
    "    eta_r = eta1[idx_r]\n",
    "    phi_l = phi1[idx_l]\n",
    "    phi_r = phi1[idx_r]\n",
    "    dphi = np.abs(phi_l - phi_r)\n",
    "    dphi[dphi > np.pi] -= 2 * np.pi  # adjust to [-pi, pi]\n",
    "    dr2 = (eta_l - eta_r)**2 + dphi**2\n",
    "\n",
    "    dr2_valid = (dr2 < DELTA_R2_CUT)\n",
    "    sim_idx_same = (simidx_l == simidx_r)\n",
    "    sim_mask = dr2_valid & sim_idx_same & (simidx_l != invalid_sim)\n",
    "    dis_mask = dr2_valid & ~sim_idx_same\n",
    "\n",
    "    sim_pairs = idxs_triu[sim_mask]\n",
    "    dis_pairs = idxs_triu[dis_mask]\n",
    "\n",
    "    # down-sample\n",
    "    if len(sim_pairs) > max_sim:\n",
    "        sim_pairs = sim_pairs[random.sample(range(len(sim_pairs)), max_sim)]\n",
    "    if len(dis_pairs) > max_dis:\n",
    "        dis_pairs = dis_pairs[random.sample(range(len(dis_pairs)), max_dis)]\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[evt {evt_idx:4d}]  T5s={n:5d}  sim={len(sim_pairs):3d}  dis={len(dis_pairs):3d} | {dt:.1f} seconds vectorized\")\n",
    "    return evt_idx, sim_pairs, dis_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-T5 pairs, comparing for-loop and vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evt    0]  T5s= 3864  sim=25040  dis=19778 | 3.5 seconds\n",
      "[evt    0]  T5s= 3864  sim=25040  dis=19778 | 0.2 seconds vectorized\n",
      "[evt    0]  sim. pairs equal: False. Equivalent: True\n",
      "[evt    0]  dis. pairs equal: True. Equivalent: True\n",
      "\n",
      "[evt    1]  T5s= 4786  sim=39667  dis=34564 | 5.4 seconds\n",
      "[evt    1]  T5s= 4786  sim=39667  dis=34564 | 0.3 seconds vectorized\n",
      "[evt    1]  sim. pairs equal: False. Equivalent: True\n",
      "[evt    1]  dis. pairs equal: True. Equivalent: True\n",
      "\n",
      "[evt    2]  T5s= 4648  sim=28559  dis=32798 | 5.1 seconds\n",
      "[evt    2]  T5s= 4648  sim=28559  dis=32798 | 0.3 seconds vectorized\n",
      "[evt    2]  sim. pairs equal: False. Equivalent: True\n",
      "[evt    2]  dis. pairs equal: True. Equivalent: True\n",
      "\n",
      "[evt    3]  T5s= 5868  sim=38960  dis=50595 | 8.1 seconds\n",
      "[evt    3]  T5s= 5868  sim=38960  dis=50595 | 0.5 seconds vectorized\n",
      "[evt    3]  sim. pairs equal: False. Equivalent: True\n",
      "[evt    3]  dis. pairs equal: True. Equivalent: True\n",
      "\n",
      "[evt    4]  T5s= 5981  sim=43421  dis=46855 | 8.4 seconds\n",
      "[evt    4]  T5s= 5981  sim=43421  dis=46855 | 0.5 seconds vectorized\n",
      "[evt    4]  sim. pairs equal: False. Equivalent: True\n",
      "[evt    4]  dis. pairs equal: True. Equivalent: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time, random, math, numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def create_t5_pairs_balanced_parallel(features_per_event,\n",
    "                                      sim_indices_per_event,\n",
    "                                      displaced_per_event,\n",
    "                                      *,\n",
    "                                      max_similar_pairs_per_event=100,\n",
    "                                      max_dissimilar_pairs_per_event=450,\n",
    "                                      invalid_sim_idx=-1,\n",
    "                                      n_workers=None):\n",
    "\n",
    "    n_evt = 5 # len(features_per_event)\n",
    "\n",
    "    for evt_idx in range(n_evt):\n",
    "        work_args = (evt_idx,\n",
    "                    features_per_event[evt_idx],\n",
    "                    sim_indices_per_event[evt_idx],\n",
    "                    displaced_per_event[evt_idx],\n",
    "                    max_similar_pairs_per_event,\n",
    "                    max_dissimilar_pairs_per_event,\n",
    "                    invalid_sim_idx,\n",
    "                    )\n",
    "\n",
    "        # run both versions\n",
    "        random.seed(42)\n",
    "        evt_idx, sim_pairs, dis_pairs = _pairs_single_event(*work_args)\n",
    "        random.seed(42)\n",
    "        evt_idx, sim_pairs_vec, dis_pairs_vec = _pairs_single_event_vectorized(*work_args)\n",
    "\n",
    "        # compare\n",
    "        sim_pairs_vec = [(i, j) for i, j in sim_pairs_vec] # de-numpify\n",
    "        dis_pairs_vec = [(i, j) for i, j in dis_pairs_vec]\n",
    "        sim_equal = (sim_pairs == sim_pairs_vec)\n",
    "        dis_equal = (dis_pairs == dis_pairs_vec)\n",
    "        sim_equiv = sorted(sim_pairs) == sorted(sim_pairs_vec)\n",
    "        dis_equiv = sorted(dis_pairs) == sorted(dis_pairs_vec)\n",
    "        print(f\"[evt {evt_idx:4d}]  sim. pairs equal: {sim_equal}. Equivalent: {sim_equiv}\")\n",
    "        print(f\"[evt {evt_idx:4d}]  dis. pairs equal: {dis_equal}. Equivalent: {dis_equiv}\")\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "# invoke\n",
    "create_t5_pairs_balanced_parallel(\n",
    "    features_per_event,\n",
    "    sim_indices_per_event,\n",
    "    displaced_per_event,\n",
    "    max_similar_pairs_per_event    = 1e6,\n",
    "    max_dissimilar_pairs_per_event = 1e6,\n",
    "    invalid_sim_idx                = -1,\n",
    "    n_workers                      = None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-PLS pairs, for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairing hyper-parameters\n",
    "DELTA_R2_CUT_PLS_T5 = 0.02\n",
    "DISP_VXY_CUT       = 0.1\n",
    "INVALID_SIM_IDX    = -1\n",
    "MAX_SIM            = 1e6 # 1000\n",
    "MAX_DIS            = 1e6 # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "\n",
    "def _pairs_pLS_T5_single(evt_idx,\n",
    "                         F_pLS, S_pLS,\n",
    "                         F_T5,  S_T5, D_T5,\n",
    "                         max_sim, max_dis,\n",
    "                         invalid_sim):\n",
    "    \"\"\"\n",
    "    Build similar / dissimilar pLS-T5 pairs for a single event,\n",
    "    printing per-event summary.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    n_p, n_t = F_pLS.shape[0], F_T5.shape[0]\n",
    "    sim_pairs, dis_pairs = [], []\n",
    "\n",
    "    # if either collection is empty, report zeros and bail\n",
    "    if n_p == 0 or n_t == 0:\n",
    "        print(f\"[evt {evt_idx:4d}]  pLSs={n_p:5d}  T5s={n_t:5d}  sim={0:4d}  dis={0:4d}\")\n",
    "        return evt_idx, []\n",
    "\n",
    "    # un-normalize eta and compute phi angles\n",
    "    eta_p = F_pLS[:,0] * 4.0\n",
    "    phi_p = np.arctan2(F_pLS[:,3], F_pLS[:,2])\n",
    "    eta_t = F_T5[:,0] * eta_max\n",
    "    phi_t = np.arctan2(F_T5[:,2], F_T5[:,1])\n",
    "\n",
    "    # bucket T5 by sim-idx for similar\n",
    "    buckets = {}\n",
    "    for j,s in enumerate(S_T5):\n",
    "        if s != invalid_sim:\n",
    "            buckets.setdefault(s, []).append(j)\n",
    "    for i,s in enumerate(S_pLS):\n",
    "        if s == invalid_sim:\n",
    "            continue\n",
    "        for j in buckets.get(s, []):\n",
    "            dphi = (phi_p[i] - phi_t[j] + np.pi) % (2*np.pi) - np.pi\n",
    "            dr2  = (eta_p[i] - eta_t[j])**2 + dphi**2\n",
    "            if dr2 < DELTA_R2_CUT_PLS_T5:\n",
    "                sim_pairs.append((i,j))\n",
    "\n",
    "    # find dissimilar (different sim-idx) pairs\n",
    "    for i in range(n_p):\n",
    "        for j in range(n_t):\n",
    "            if S_pLS[i] == S_T5[j] and S_pLS[i] != invalid_sim:\n",
    "                continue\n",
    "            dphi = (phi_p[i] - phi_t[j] + np.pi) % (2*np.pi) - np.pi\n",
    "            dr2  = (eta_p[i] - eta_t[j])**2 + dphi**2\n",
    "            if dr2 < DELTA_R2_CUT_PLS_T5:\n",
    "                dis_pairs.append((i,j))\n",
    "\n",
    "    # down-sample to limits\n",
    "    if len(sim_pairs) > max_sim:\n",
    "        sim_pairs = random.sample(sim_pairs, max_sim)\n",
    "    if len(dis_pairs) > max_dis:\n",
    "        dis_pairs = random.sample(dis_pairs, max_dis)\n",
    "\n",
    "    # print per-event summary\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[evt {evt_idx:4d}]  pLSs={n_p:5d}  T5s={n_t:5d}  \"\n",
    "          f\"sim={len(sim_pairs):4d}  dis={len(dis_pairs):4d} | {dt:.1f} seconds vectorized\")\n",
    "\n",
    "    # pack into (feature, feature, label, displaced_flag)\n",
    "    packed = []\n",
    "    for i,j in sim_pairs:\n",
    "        packed.append((F_pLS[i], F_T5[j], 0, D_T5[j] > DISP_VXY_CUT))\n",
    "    for i,j in dis_pairs:\n",
    "        packed.append((F_pLS[i], F_T5[j], 1, D_T5[j] > DISP_VXY_CUT))\n",
    "\n",
    "    return evt_idx, packed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-PLS pairs, vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairs_pLS_T5_single_vectorized(evt_idx,\n",
    "                                    F_pLS, S_pLS,\n",
    "                                    F_T5,  S_T5, D_T5,\n",
    "                                    max_sim, max_dis,\n",
    "                                    invalid_sim):\n",
    "    \"\"\"\n",
    "    Build similar / dissimilar pLS-T5 pairs for a single event,\n",
    "    printing per-event summary.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    n_p, n_t = F_pLS.shape[0], F_T5.shape[0]\n",
    "    sim_pairs, dis_pairs = [], []\n",
    "\n",
    "    # if either collection is empty, report zeros and bail\n",
    "    if n_p == 0 or n_t == 0:\n",
    "        print(f\"[evt {evt_idx:4d}]  pLSs={n_p:5d}  T5s={n_t:5d}  sim={0:4d}  dis={0:4d}\")\n",
    "        return evt_idx, []\n",
    "\n",
    "    # un-normalize eta and compute phi angles\n",
    "    eta_p = F_pLS[:,0] * 4.0\n",
    "    phi_p = np.arctan2(F_pLS[:,3], F_pLS[:,2])\n",
    "    eta_t = F_T5[:,0] * eta_max\n",
    "    phi_t = np.arctan2(F_T5[:,2], F_T5[:,1])\n",
    "\n",
    "    # make all possible pairs (i, j)\n",
    "    idx_p, idx_t = np.indices( (n_p, n_t) )\n",
    "    idx_p, idx_t = idx_p.flatten(), idx_t.flatten()\n",
    "\n",
    "    # calculate angles\n",
    "    dphi = (phi_p[idx_p] - phi_t[idx_t] + np.pi) % (2 * np.pi) - np.pi\n",
    "    dr2 = (eta_p[idx_p] - eta_t[idx_t])**2 + dphi**2\n",
    "    dr2_valid = (dr2 < DELTA_R2_CUT_PLS_T5)\n",
    "\n",
    "    # compare sim indices\n",
    "    simidx_p = S_pLS[idx_p]\n",
    "    simidx_t = S_T5[idx_t]\n",
    "    sim_idx_same = (simidx_p == simidx_t)\n",
    "\n",
    "    # create masks for similar and dissimilar pairs\n",
    "    sim_mask = dr2_valid & sim_idx_same & (simidx_p != invalid_sim)\n",
    "    dis_mask = dr2_valid & ~sim_idx_same\n",
    "\n",
    "    # get the pairs\n",
    "    sim_pairs = np.column_stack((idx_p[sim_mask], idx_t[sim_mask]))\n",
    "    dis_pairs = np.column_stack((idx_p[dis_mask], idx_t[dis_mask]))\n",
    "\n",
    "    # down-sample\n",
    "    if len(sim_pairs) > max_sim:\n",
    "        sim_pairs = sim_pairs[random.sample(range(len(sim_pairs)), max_sim)]\n",
    "    if len(dis_pairs) > max_dis:\n",
    "        dis_pairs = dis_pairs[random.sample(range(len(dis_pairs)), max_dis)]\n",
    "\n",
    "    # print per-event summary\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[evt {evt_idx:4d}]  pLSs={n_p:5d}  T5s={n_t:5d}  \"\n",
    "          f\"sim. pairs={len(sim_pairs):4d}  dis. pairs={len(dis_pairs):4d} | {dt:.1f} seconds vectorized\")\n",
    "\n",
    "\n",
    "    # pack into (feature, feature, label, displaced_flag)\n",
    "    packed = []\n",
    "    for i,j in sim_pairs:\n",
    "        packed.append((F_pLS[i], F_T5[j], 0, D_T5[j] > DISP_VXY_CUT))\n",
    "    for i,j in dis_pairs:\n",
    "        packed.append((F_pLS[i], F_T5[j], 1, D_T5[j] > DISP_VXY_CUT))\n",
    "\n",
    "    return evt_idx, packed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-PLS pairs, comparing for-loop and vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evt    0]  pLSs= 4837  T5s= 3864  sim=5566  dis=11187 | 12.4 seconds vectorized\n",
      "[evt    0]  pLSs= 4837  T5s= 3864  sim. pairs=5566  dis. pairs=11187 | 0.4 seconds vectorized\n",
      "[evt    0]  pLS-T5 pairs equal: True\n",
      "\n",
      "[evt    1]  pLSs= 5349  T5s= 4786  sim=7691  dis=20348 | 17.1 seconds vectorized\n",
      "[evt    1]  pLSs= 5349  T5s= 4786  sim. pairs=7691  dis. pairs=20348 | 0.6 seconds vectorized\n",
      "[evt    1]  pLS-T5 pairs equal: True\n",
      "\n",
      "[evt    2]  pLSs= 6306  T5s= 4648  sim=7480  dis=19931 | 19.5 seconds vectorized\n",
      "[evt    2]  pLSs= 6306  T5s= 4648  sim. pairs=7480  dis. pairs=19931 | 0.7 seconds vectorized\n",
      "[evt    2]  pLS-T5 pairs equal: True\n",
      "\n",
      "[evt    3]  pLSs= 5885  T5s= 5868  sim=8893  dis=28644 | 23.1 seconds vectorized\n",
      "[evt    3]  pLSs= 5885  T5s= 5868  sim. pairs=8893  dis. pairs=28644 | 0.8 seconds vectorized\n",
      "[evt    3]  pLS-T5 pairs equal: True\n",
      "\n",
      "[evt    4]  pLSs= 6463  T5s= 5981  sim=8938  dis=21937 | 25.9 seconds vectorized\n",
      "[evt    4]  pLSs= 6463  T5s= 5981  sim. pairs=8938  dis. pairs=21937 | 0.9 seconds vectorized\n",
      "[evt    4]  pLS-T5 pairs equal: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_evt = 5 # len(features_per_event)\n",
    "\n",
    "for evt_idx in range(n_evt):\n",
    "    works_args = (\n",
    "        evt_idx,\n",
    "        pLS_features_per_event[evt_idx],\n",
    "        pLS_sim_indices_per_event[evt_idx],\n",
    "        features_per_event[evt_idx],\n",
    "        sim_indices_per_event[evt_idx],\n",
    "        displaced_per_event[evt_idx],\n",
    "        MAX_SIM, MAX_DIS, INVALID_SIM_IDX,\n",
    "        )\n",
    "\n",
    "    # run both versions\n",
    "    random.seed(42)\n",
    "    _, packed = _pairs_pLS_T5_single(*works_args)\n",
    "    random.seed(42)\n",
    "    _, packed_vec = _pairs_pLS_T5_single_vectorized(*works_args)\n",
    "\n",
    "    # compare\n",
    "    def tup_equal(a, b):\n",
    "        return (np.array_equal(a[0], b[0]) and\n",
    "                np.array_equal(a[1], b[1]) and\n",
    "                a[2] == b[2] and\n",
    "                np.array_equal(a[3], b[3]))\n",
    "    \n",
    "    def packed_equal(a, b):\n",
    "        if len(a) != len(b):\n",
    "            return False\n",
    "        for (a_i, b_i) in zip(a, b):\n",
    "            if not tup_equal(a_i, b_i):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    equal = packed_equal(packed, packed_vec)\n",
    "    print(f\"[evt {evt_idx:4d}]  pLS-T5 pairs equal: {equal}\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
